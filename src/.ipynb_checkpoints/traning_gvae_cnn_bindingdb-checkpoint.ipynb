{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install git+https://github.com/bp-kelley/descriptastorus\n",
    "# %pip install DeepPurpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 23:05:39.418599: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-17 23:06:15.547428: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-07-17 23:06:15.562743: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-07-17 23:06:17.545854: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-17 23:07:11.043737: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-07-17 23:07:11.044600: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-07-17 23:07:11.044630: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from DeepPurpose import utils, dataset\n",
    "from DeepPurpose import DTI as models\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset from path...\n",
      "Beginning Processing...\n",
      "There are 91751 drug target pairs.\n",
      "Default set to logspace (nM -> p) for easier regression\n",
      "Drug 1: Cc1ccc(CNS(=O)(=O)c2ccc(s2)S(N)(=O)=O)cc1\n",
      "Target 1: MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKPLSVSYDQATSLRILNNGHAFNVEFDDSQDKAVLKGGPLDGTYRLIQFHFHWGSLDGQGSEHTVDKKKYAAELHLVHWNTKYGDFGKAVQQPDGLAVLGIFLKVGSAKPGLQKVVDVLDSIKTKGKSADFTNFDPRGLLPESLDYWTYPGSLTTPPLLECVTWIVLKEPISVSSEQVLKFRKLNFNGEGEPEELMVDNWRPAQPLKNRQIKASFK\n",
      "Score 1: 9.337242168318426\n"
     ]
    }
   ],
   "source": [
    "# Preprocess BindingDB dataset\n",
    "X_drugs, X_targets, y = dataset.process_BindingDB(path='../data/BindingDB/')\n",
    "print('Drug 1: ' + X_drugs[0])\n",
    "print('Target 1: ' + X_targets[0])\n",
    "print('Score 1: ' + str(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                Cc1ccc(CNS(=O)(=O)c2ccc(s2)S(N)(=O)=O)cc1\n",
       "1               COc1ccc(CNS(=O)(=O)c2ccc(s2)S(N)(=O)=O)cc1\n",
       "2                    NS(=O)(=O)c1ccc(s1)S(=O)(=O)NCc1cccs1\n",
       "3             NS(=O)(=O)c1cc2C(O)CN(Cc3cccs3)S(=O)(=O)c2s1\n",
       "4           COc1ccc(cc1)N1CC(O)c2cc(sc2S1(=O)=O)S(N)(=O)=O\n",
       "                               ...                        \n",
       "91746    COc1cc(cc(OC)c1CN1CCN(CCCCCOc2cc(ccc2CNC(=O)[C...\n",
       "91747    COc1cc(cc(OC)c1CN1CCN(CCOCCOCCOc2cc(ccc2CNC(=O...\n",
       "91748    CC(C)(O)[C@H]1CC[C@@H](CC1)NC(=O)c1cnc2nc(ccc2...\n",
       "91749    COc1cc(ccc1Nc1ncc2NC(=O)c3ccccc3N(C)c2n1)N1CCN...\n",
       "91750    Cc1nc(Nc2ncc(s2)C(=O)Nc2c(C)cccc2Cl)cc(n1)N1CC...\n",
       "Length: 91751, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_drugs = pd.Series(X_drugs)\n",
    "X_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91751, 277, 76)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding of drug SMILES\n",
    "S = pd.Series(X_drugs.unique()).apply(utils.smiles2onehot)\n",
    "S_dict = dict(zip(X_drugs.unique(), S))\n",
    "df_drugs = [S_dict[i] for i in X_drugs]\n",
    "one_hot_drugs = np.array(df_drugs)\n",
    "one_hot_drugs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...\n",
       "1        MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...\n",
       "2        MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...\n",
       "3        MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...\n",
       "4        MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...\n",
       "                               ...                        \n",
       "91746    MDGEEKTYGGCEGPDAMYVKLISSDGHEFIVKREHALTSGTIKAML...\n",
       "91747    MDGEEKTYGGCEGPDAMYVKLISSDGHEFIVKREHALTSGTIKAML...\n",
       "91748    MPNYKLTYFNMRGRAEIIRYIFAYLDIQYEDHRIEQADWPEIKSTL...\n",
       "91749    MQPEEGTGWLLELLSEVQLQQYFLRLRDDLNVTRLSHFEYVKNEDL...\n",
       "91750    MQPEEGTGWLLELLSEVQLQQYFLRLRDDLNVTRLSHFEYVKNEDL...\n",
       "Length: 91751, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_targets = pd.Series(X_targets)\n",
    "X_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91751, 26, 1000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding of proteins\n",
    "AA = pd.Series(X_targets.unique()).apply(utils.protein2onehot)\n",
    "AA_dict = dict(zip(X_targets.unique(), AA))\n",
    "df_proteins = [AA_dict[i] for i in X_targets]\n",
    "one_hot_proteins = np.array(df_proteins)\n",
    "one_hot_proteins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91751,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - GVAE + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 23:26:46.951199: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-07-17 23:26:46.954539: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-07-17 23:26:46.955268: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-07-17 23:26:46.956960: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-07-17 23:26:47.136753: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-07-17 23:26:47.137676: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-07-17 23:26:47.525161: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import utils\n",
    "from predictor_gvae_rnaseq_cnn import DLEPS\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable\n",
    "import h5py\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Clean data to remove inf, nan, if present any\n",
    "drugs = utils.clean_data(one_hot_drugs, fill_value=0)\n",
    "# genes = utils.clean_data(genes, fill_value=0)\n",
    "proteins = utils.clean_data(one_hot_proteins, fill_value=0)\n",
    "labels = utils.clean_data(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "drug_train, protein_train, y_train, \\\n",
    "drug_val, protein_val, y_val, \\\n",
    "drug_test, protein_test, y_test = utils.train_val_test_split(X1=drugs, X3=proteins, y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64225, 277, 76) (13762, 277, 76) (13764, 277, 76)\n",
      "(64225, 26, 1000) (13762, 26, 1000) (13764, 26, 1000)\n",
      "(64225,) (13762,) (13764,)\n"
     ]
    }
   ],
   "source": [
    "print(drug_train.shape, drug_val.shape, drug_test.shape)\n",
    "print(protein_train.shape, protein_val.shape, protein_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: cuDNN\n"
     ]
    }
   ],
   "source": [
    "%pip show cuDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 26, 1000)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 26, 32)       128032      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 277, 76)]    0           []                               \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 13, 32)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_1 (Conv1D)                (None, 269, 9)       6165        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 978, 2)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 13, 64)       16448       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv_2 (Conv1D)                (None, 261, 9)       738         ['conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1956)         0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 7, 64)       0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv_3 (Conv1D)                (None, 251, 10)      1000        ['conv_2[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          500992      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 7, 96)        73824       ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_11 (Flatten)           (None, 2510)         0           ['conv_3[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 4, 96)       0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 435)          1092285     ['flatten_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          32896       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 96)          0           ['max_pooling1d_2[0][0]']        \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 56)           24416       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 56)           24416       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 56)           5432        ['global_max_pooling1d[0][0]']   \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 56)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 56)           7224        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 56)           3192        ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 168)          0           ['lambda[0][0]',                 \n",
      "                                                                  'dense_4[0][0]',                \n",
      "                                                                  'dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1024)         173056      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1024)         0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1024)         1049600     ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 1024)         0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 512)          524800      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 512)          0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 1)            513         ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,665,029\n",
      "Trainable params: 3,665,029\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "# Load model\n",
    "dleps_p = DLEPS()\n",
    "model = dleps_p.model[0]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function\n",
    "def train(): \n",
    "    # Training start time\n",
    "    tr_start = time.time()\n",
    "    print(\"----START TRAINING----\")\n",
    "    # compile the model\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae']) \n",
    "\n",
    "    # Use ModelCheckpoint to save model and weights\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "    # filepath = \"test.weights.complete.cnn.best.hdf5\"\n",
    "    # filepath = \"../../model_weights/test.weights.complete.cnn.hdf5\"\n",
    "    filepath = \"../../model_weights/sample_x.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "    # train the model\n",
    "    epochs = 100\n",
    "    batch_size = 256\n",
    "    early_stopping = EarlyStopping(monitor='val_mae', patience=10)\n",
    "    history = model.fit([drug_train, protein_train], y_train, batch_size=batch_size, epochs=epochs, callbacks=[checkpoint, early_stopping], validation_data=([drug_val, protein_val], y_val))\n",
    "\n",
    "    # Plot the training and validation loss\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title(\"Loss Curve: Drug Encoding = GVAE, Protein Encoding = CNN\")\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"../../results/loss_gvae_cnn.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Plot the training and validation MAE\n",
    "    plt.title(\"MAE Curve: Drug Encoding = GVAE, Protein Encoding = CNN\")\n",
    "    plt.plot(history.history['mae'], label='Train MAE')\n",
    "    plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"../../results/mae_gvae_cnn.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"----END TRAINING----\")\n",
    "    tr_end = time.time()\n",
    "    print(f'Elapsed time for training: {tr_end - tr_start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    print('----LOAD PRETRAINED MODEL----')\n",
    "    # model.load_weights(\"../../model_weights/test.weights.complete.cnn.hdf5\")\n",
    "    model.load_weights(\"../../model_weights/test.weights.complete.hdf5\")\n",
    "    print('----PRETRAINED MODEL LOADED----')\n",
    "    print('----START TESTING----')\n",
    "\n",
    "    y_pred_val = model.predict([drug_val, gene_val, protein_val])\n",
    "    y_pred_test = model.predict([drug_test, gene_test, protein_test])\n",
    "\n",
    "    # Validation results\n",
    "    val_mse_loss = utils.mse_loss(y_val, y_pred_val.ravel())\n",
    "    val_pearson_corr = utils.pearson_correlation(y_val, y_pred_val.ravel())\n",
    "    val_c_index = utils.c_index(y_val, y_pred_val.ravel())\n",
    "\n",
    "    # Test results\n",
    "    test_mse_loss = utils.mse_loss(y_test, y_pred_test.ravel())\n",
    "    test_pearson_corr = utils.pearson_correlation(y_test, y_pred_test.ravel())\n",
    "    test_c_index = utils.c_index(y_test, y_pred_test.ravel())\n",
    "\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Metric\", \"Validation\", \"Test\"]\n",
    "    table.add_row([\"MSE Loss\", val_mse_loss, test_mse_loss])\n",
    "    table.add_row([\"Pearson Correlation\", val_pearson_corr, test_pearson_corr])\n",
    "    table.add_row([\"Concordance Index\", val_c_index, test_c_index])\n",
    "\n",
    "    # Print results\n",
    "    print(table)\n",
    "\n",
    "    # Plot validation results\n",
    "    plt.scatter(y_val, y_pred_val)\n",
    "    m, b = np.polyfit(y_val, y_pred_val, 1)\n",
    "    plt.plot(y_val, m * y_val + b, 'r')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title('Actual vs Predicted')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot validation results\n",
    "    plt.scatter(y_test, y_pred_test)\n",
    "    m, b = np.polyfit(y_test, y_pred_test, 1)\n",
    "    plt.plot(y_test, m * y_test + b, 'r')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title('Actual vs Predicted')\n",
    "    plt.show()\n",
    "    print('----END TESTING----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(mode):\n",
    "    if mode == 'train':\n",
    "        train()\n",
    "    elif mode == 'test':\n",
    "        test()\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be either 'train' or 'test'.\")\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(description=\"train or test\")\n",
    "#     parser.add_argument('--mode', type=str, choices=['train', 'test'], required=True, help=\"Mode to run: 'train' or 'test'\")\n",
    "#     parser.add_argument('--log', type=str, help=\"Log file name\")\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     # Save results to log file\n",
    "#     logging.basicConfig(filename=args.log, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "#     # Run\n",
    "#     main(args.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----START TRAINING----\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(mode):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 3\u001b[0m         \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      5\u001b[0m         test()\n",
      "Cell \u001b[1;32mIn[15], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[0;32m     20\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mae\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdrug_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotein_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdrug_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotein_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Plot the training and validation loss\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32md:\\drug_repurp\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\drug_repurp\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "mode = 'train'\n",
    "main(mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
